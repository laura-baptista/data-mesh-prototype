services:
  # =======================
  # Infraestrutura base
  # =======================
  zookeeper:
    image: wurstmeister/zookeeper
    profiles: ["kafka", "full"]
    container_name: zookeeper
    restart: always
    ports:
      - '2181:2181'
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    image: wurstmeister/kafka
    profiles: ["kafka", "full"]    
    container_name: kafka
    restart: always
    ports:
      - '9092:9092'
      - '9093:9093'
    environment:
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_ADVERTISED_LISTENERS=INTERNAL://kafka:9092,EXTERNAL://localhost:9093
      - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_LISTENERS=INTERNAL://:9092,EXTERNAL://:9093
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
    depends_on:
      - zookeeper
    healthcheck:
      test: [ "CMD", "kafka-topics.sh", "--list", "--bootstrap-server", "kafka:9092" ]
      interval: 30s
      timeout: 10s
      retries: 4

  topic-creator:
    profiles: ["kafka", "full"]
    build: ./kafka
    depends_on:
      - kafka
    restart: "on-failure"

  # =======================
  # Processamento
  # =======================
  spark:
    profiles: ["full"]
    image: apache/spark:3.5.0
    container_name: spark
    restart: always
    ports:
      - "7077:7077"
      - "8080:8080"
    environment:
      - SPARK_MODE=master
    volumes:
      - ./spark/app:/opt/spark-apps
    networks:
      - data-mesh

  flink:
    profiles: ["full"]
    image: flink:latest # A priori, deixei latest
    container_name: flink
    restart: always
    ports:
      - "8081:8081"
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink
    networks:
      - data-mesh
    
  # =======================
  # Orquestração
  # =======================
  airflow:
    profiles: ["full"]
    image: apache/airflow:latest # A priori, deixei latest
    container_name: airflow
    restart: always
    ports:
      - "8082:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__FERNET_KEY=fernet_key
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    networks:
      - data-mesh

  # =======================
  # Consulta e Visualização
  # =======================
  dremio:
    profiles: ["full"]
    image: dremio/dremio-oss:latest # A priori, deixei latest
    container_name: dremio
    restart: always
    ports:
      - "9047:9047"
      - "31010:31010"
    volumes:
      - ./dremio:/opt/dremio/data
    networks:
      - data-mesh

  metabase:
    profiles: ["full"]
    image: metabase/metabase
    container_name: metabase
    restart: always
    ports:
      - "3000:3000"
    environment:
      - MB_DB_FILE=/metabase.db
    volumes:
      - ./metabase:/metabase.db
    networks:
      - data-mesh

networks:
  data-mesh:
    driver: bridge
